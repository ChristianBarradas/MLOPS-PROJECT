{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGPMlqIWKQKT"
      },
      "source": [
        "# Predicting House Prices (Keras - Artificial Neural Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kYGB2nGKQKY"
      },
      "source": [
        "### Setups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cPsoJA10KQKY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# scaling and train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# creating a model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# evaluation on test data\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Constans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASETS_DIR = '/Users/SISTEMAS/MLOPs_Project/DataSet/kc_house_data.csv'\n",
        "COLUMNS_TO_DROP = ['id', 'zipcode', 'date']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custum Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    #the constructor\n",
        "    '''setting the add_bedrooms_per_room to True helps us check if the hyperparameter is useful'''\n",
        "    def __init__(self, add_bedrooms_per_room = True):\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    #estimator method\n",
        "    def fit(self, X, y = None):\n",
        "        return self\n",
        "    #transfprmation\n",
        "    def transform(self, X, y = None):\n",
        "        #agregar 2 columnas\n",
        "        X_copy = X.copy()\n",
        "        X_copy['date'] = pd.to_datetime(X_copy['date'])\n",
        "        X_copy['month'] = X_copy['date'].apply(lambda date: date.month)\n",
        "        X_copy['year'] = X_copy['date'].apply(lambda date: date.year)\n",
        "        #X_copy = X_copy.drop('date', axis=1)\n",
        "        return X_copy\n",
        "\n",
        "    \n",
        "#Agregar_Caracteristicas = CustomTransformer()\n",
        "#DataSet = Agregar_Caracteristicas.transform(df)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.COLUMNS_TO_DROP = COLUMNS_TO_DROP\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X_copy = X.drop(self.COLUMNS_TO_DROP, axis=1)\n",
        "        return X_copy\n",
        "\n",
        "# Instanciar el custom transformer\n",
        "#drop_columns_transformer = DropColumnsTransformer(COLUMNS_TO_DROP)\n",
        "    \n",
        "    # Transformar los datos\n",
        "#transformed_data = drop_columns_transformer.transform(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomMinMaxScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        # Ajusta el escalador en los datos de entrenamiento\n",
        "        self.scaler.fit(X)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Transforma los datos usando el escalador ajustado\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return X_scaled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATASETS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "House_Price_Pipeline = Pipeline([\n",
        "        ('Agregar_Variables',CustomTransformer()),\n",
        "        ('DropColumns',DropColumnsTransformer()),\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = House_Price_Pipeline.fit_transform(df)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('price',axis=1),\n",
        "                                                    df['price'],test_size=0.3,random_state=101\n",
        "                                                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15129, 19)\n",
            "(6484, 19)\n",
            "(15129,)\n",
            "(6484,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit and transfrom\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#preguntar-MinMaxScaler_Pipeline = Pipeline([\n",
        " #       ('Scalar',CustomMinMaxScaler()),\n",
        "  #      ])\n",
        "\n",
        "#X_train = MinMaxScaler_Pipeline.fit_transform(X_train)        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fEi8Q92KQKo"
      },
      "source": [
        "<a id=\"ch7\"></a>\n",
        "## Creating a model\n",
        "***\n",
        "We estimate the number of neurons (units) from our features. Ex: X_train.shape (15117, 19). The optimizer is asking how you want to perform this gradient descent. In this case we are using the Adam optimizer and the mean square error loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hpblBCzxKQKo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "model.add(Dense(19,activation='relu'))\n",
        "\n",
        "# hidden layers\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g2L52S5KQKo"
      },
      "source": [
        "\n",
        "## Training the model\n",
        "Now that the model is ready, we can fit the model into the data.\n",
        "\n",
        "Since the dataset is large, we are going to use batch_size. It is typical to use batches of the power of 2 (32, 64, 128, 256...). In this case we are using 128. The smaller the batch size, the longer is going to take."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "_kg_hide-output": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aMW9kLP6KQKo",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f690a610-a617-4d03-a1aa-701db6dea9f4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 423609434112.0000 - val_loss: 432928194560.0000\n",
            "Epoch 2/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 421928337408.0000 - val_loss: 427347673088.0000\n",
            "Epoch 3/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 401891033088.0000 - val_loss: 382281121792.0000\n",
            "Epoch 4/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 312255741952.0000 - val_loss: 241216552960.0000\n",
            "Epoch 5/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 160572080128.0000 - val_loss: 116006772736.0000\n",
            "Epoch 6/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 101370503168.0000 - val_loss: 104035074048.0000\n",
            "Epoch 7/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 97954070528.0000 - val_loss: 102292463616.0000\n",
            "Epoch 8/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 96373039104.0000 - val_loss: 100629078016.0000\n",
            "Epoch 9/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 94783750144.0000 - val_loss: 98905980928.0000\n",
            "Epoch 10/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 93215408128.0000 - val_loss: 97113964544.0000\n",
            "Epoch 11/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 91566407680.0000 - val_loss: 95372869632.0000\n",
            "Epoch 12/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 89861619712.0000 - val_loss: 93456334848.0000\n",
            "Epoch 13/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 88111538176.0000 - val_loss: 91553923072.0000\n",
            "Epoch 14/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 86287982592.0000 - val_loss: 89447702528.0000\n",
            "Epoch 15/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 84340596736.0000 - val_loss: 87346749440.0000\n",
            "Epoch 16/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 82283528192.0000 - val_loss: 85065662464.0000\n",
            "Epoch 17/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 80131612672.0000 - val_loss: 82634735616.0000\n",
            "Epoch 18/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 77891829760.0000 - val_loss: 80121970688.0000\n",
            "Epoch 19/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 75527118848.0000 - val_loss: 77539262464.0000\n",
            "Epoch 20/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 73066037248.0000 - val_loss: 74785587200.0000\n",
            "Epoch 21/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 70556385280.0000 - val_loss: 72032976896.0000\n",
            "Epoch 22/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 68055113728.0000 - val_loss: 69284175872.0000\n",
            "Epoch 23/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 65606074368.0000 - val_loss: 66645188608.0000\n",
            "Epoch 24/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 63262359552.0000 - val_loss: 64056385536.0000\n",
            "Epoch 25/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 61090344960.0000 - val_loss: 61689266176.0000\n",
            "Epoch 26/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 59108900864.0000 - val_loss: 59642085376.0000\n",
            "Epoch 27/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 57349181440.0000 - val_loss: 57747083264.0000\n",
            "Epoch 28/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 55871623168.0000 - val_loss: 56269316096.0000\n",
            "Epoch 29/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 54618054656.0000 - val_loss: 55091798016.0000\n",
            "Epoch 30/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 53619691520.0000 - val_loss: 53964898304.0000\n",
            "Epoch 31/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 52634755072.0000 - val_loss: 52837449728.0000\n",
            "Epoch 32/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 51799638016.0000 - val_loss: 51936059392.0000\n",
            "Epoch 33/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 51085873152.0000 - val_loss: 51248410624.0000\n",
            "Epoch 34/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 50477985792.0000 - val_loss: 50583212032.0000\n",
            "Epoch 35/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 49850572800.0000 - val_loss: 49877426176.0000\n",
            "Epoch 36/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 49264381952.0000 - val_loss: 49322979328.0000\n",
            "Epoch 37/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 48688025600.0000 - val_loss: 48755408896.0000\n",
            "Epoch 38/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 48199495680.0000 - val_loss: 48216330240.0000\n",
            "Epoch 39/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 47723274240.0000 - val_loss: 47729016832.0000\n",
            "Epoch 40/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 47256395776.0000 - val_loss: 47320846336.0000\n",
            "Epoch 41/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 46807003136.0000 - val_loss: 46818390016.0000\n",
            "Epoch 42/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 46381068288.0000 - val_loss: 46381219840.0000\n",
            "Epoch 43/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 45984698368.0000 - val_loss: 45983145984.0000\n",
            "Epoch 44/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 45596360704.0000 - val_loss: 45607272448.0000\n",
            "Epoch 45/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 45259071488.0000 - val_loss: 45392957440.0000\n",
            "Epoch 46/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 44880060416.0000 - val_loss: 44869210112.0000\n",
            "Epoch 47/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 44514148352.0000 - val_loss: 44618596352.0000\n",
            "Epoch 48/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 44266876928.0000 - val_loss: 44189069312.0000\n",
            "Epoch 49/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 43882106880.0000 - val_loss: 44007206912.0000\n",
            "Epoch 50/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 43563859968.0000 - val_loss: 43619995648.0000\n",
            "Epoch 51/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 43234451456.0000 - val_loss: 43183243264.0000\n",
            "Epoch 52/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 42915594240.0000 - val_loss: 42915033088.0000\n",
            "Epoch 53/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 42623148032.0000 - val_loss: 42662297600.0000\n",
            "Epoch 54/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 42328219648.0000 - val_loss: 42277584896.0000\n",
            "Epoch 55/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 42113839104.0000 - val_loss: 42022006784.0000\n",
            "Epoch 56/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 41845374976.0000 - val_loss: 41775247360.0000\n",
            "Epoch 57/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 41564033024.0000 - val_loss: 41458569216.0000\n",
            "Epoch 58/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 41304530944.0000 - val_loss: 41190305792.0000\n",
            "Epoch 59/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 41057271808.0000 - val_loss: 40895709184.0000\n",
            "Epoch 60/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 40835932160.0000 - val_loss: 40635043840.0000\n",
            "Epoch 61/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 40612360192.0000 - val_loss: 40355192832.0000\n",
            "Epoch 62/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 40300736512.0000 - val_loss: 40106803200.0000\n",
            "Epoch 63/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 40105132032.0000 - val_loss: 39912443904.0000\n",
            "Epoch 64/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 39897616384.0000 - val_loss: 39675514880.0000\n",
            "Epoch 65/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39653662720.0000 - val_loss: 39492071424.0000\n",
            "Epoch 66/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39489204224.0000 - val_loss: 39275978752.0000\n",
            "Epoch 67/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 39311466496.0000 - val_loss: 39063105536.0000\n",
            "Epoch 68/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 39110893568.0000 - val_loss: 38904455168.0000\n",
            "Epoch 69/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38922612736.0000 - val_loss: 38762475520.0000\n",
            "Epoch 70/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38756589568.0000 - val_loss: 38462525440.0000\n",
            "Epoch 71/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38602502144.0000 - val_loss: 38327476224.0000\n",
            "Epoch 72/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38420758528.0000 - val_loss: 38079827968.0000\n",
            "Epoch 73/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38206013440.0000 - val_loss: 37891080192.0000\n",
            "Epoch 74/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 38065963008.0000 - val_loss: 37774036992.0000\n",
            "Epoch 75/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 37921058816.0000 - val_loss: 37548482560.0000\n",
            "Epoch 76/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 37735641088.0000 - val_loss: 37537034240.0000\n",
            "Epoch 77/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 37604614144.0000 - val_loss: 37241389056.0000\n",
            "Epoch 78/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 37461499904.0000 - val_loss: 37092384768.0000\n",
            "Epoch 79/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 37362536448.0000 - val_loss: 36968132608.0000\n",
            "Epoch 80/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 37152407552.0000 - val_loss: 36829102080.0000\n",
            "Epoch 81/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 37056913408.0000 - val_loss: 36643315712.0000\n",
            "Epoch 82/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 36901101568.0000 - val_loss: 36521549824.0000\n",
            "Epoch 83/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36779728896.0000 - val_loss: 36386799616.0000\n",
            "Epoch 84/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 36664500224.0000 - val_loss: 36253265920.0000\n",
            "Epoch 85/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 36572884992.0000 - val_loss: 36078964736.0000\n",
            "Epoch 86/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 36405780480.0000 - val_loss: 36007714816.0000\n",
            "Epoch 87/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36296409088.0000 - val_loss: 35847757824.0000\n",
            "Epoch 88/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36181364736.0000 - val_loss: 35757391872.0000\n",
            "Epoch 89/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 36096647168.0000 - val_loss: 35593801728.0000\n",
            "Epoch 90/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35974463488.0000 - val_loss: 35502886912.0000\n",
            "Epoch 91/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35886116864.0000 - val_loss: 35383529472.0000\n",
            "Epoch 92/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35799019520.0000 - val_loss: 35306618880.0000\n",
            "Epoch 93/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35709665280.0000 - val_loss: 35201785856.0000\n",
            "Epoch 94/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35628544000.0000 - val_loss: 35124932608.0000\n",
            "Epoch 95/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35535749120.0000 - val_loss: 35019141120.0000\n",
            "Epoch 96/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35453722624.0000 - val_loss: 34939314176.0000\n",
            "Epoch 97/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35356942336.0000 - val_loss: 34828849152.0000\n",
            "Epoch 98/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35273097216.0000 - val_loss: 34746888192.0000\n",
            "Epoch 99/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35232514048.0000 - val_loss: 34669465600.0000\n",
            "Epoch 100/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35166158848.0000 - val_loss: 34622337024.0000\n",
            "Epoch 101/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 35076595712.0000 - val_loss: 34526982144.0000\n",
            "Epoch 102/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 35018960896.0000 - val_loss: 34472632320.0000\n",
            "Epoch 103/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34987261952.0000 - val_loss: 34383020032.0000\n",
            "Epoch 104/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34908315648.0000 - val_loss: 34339162112.0000\n",
            "Epoch 105/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34849140736.0000 - val_loss: 34254243840.0000\n",
            "Epoch 106/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34750803968.0000 - val_loss: 34258403328.0000\n",
            "Epoch 107/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34735341568.0000 - val_loss: 34129139712.0000\n",
            "Epoch 108/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34634825728.0000 - val_loss: 34135750656.0000\n",
            "Epoch 109/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34592808960.0000 - val_loss: 34046621696.0000\n",
            "Epoch 110/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34556313600.0000 - val_loss: 34009903104.0000\n",
            "Epoch 111/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34479353856.0000 - val_loss: 33968371712.0000\n",
            "Epoch 112/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 34539003904.0000 - val_loss: 33854095360.0000\n",
            "Epoch 113/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34353831936.0000 - val_loss: 33818990592.0000\n",
            "Epoch 114/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 34343677952.0000 - val_loss: 33883549696.0000\n",
            "Epoch 115/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34379411456.0000 - val_loss: 33761771520.0000\n",
            "Epoch 116/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 34238482432.0000 - val_loss: 33657794560.0000\n",
            "Epoch 117/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34207055872.0000 - val_loss: 33591482368.0000\n",
            "Epoch 118/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34127366144.0000 - val_loss: 33535797248.0000\n",
            "Epoch 119/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34097375232.0000 - val_loss: 33497237504.0000\n",
            "Epoch 120/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34095618048.0000 - val_loss: 33447688192.0000\n",
            "Epoch 121/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 34008547328.0000 - val_loss: 33394485248.0000\n",
            "Epoch 122/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33989668864.0000 - val_loss: 33356388352.0000\n",
            "Epoch 123/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33915271168.0000 - val_loss: 33305909248.0000\n",
            "Epoch 124/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33876400128.0000 - val_loss: 33281173504.0000\n",
            "Epoch 125/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33828788224.0000 - val_loss: 33198497792.0000\n",
            "Epoch 126/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33771978752.0000 - val_loss: 33160337408.0000\n",
            "Epoch 127/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33704028160.0000 - val_loss: 33194868736.0000\n",
            "Epoch 128/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33723863040.0000 - val_loss: 33079228416.0000\n",
            "Epoch 129/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33670412288.0000 - val_loss: 33024595968.0000\n",
            "Epoch 130/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33667874816.0000 - val_loss: 33126105088.0000\n",
            "Epoch 131/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33612683264.0000 - val_loss: 32942788608.0000\n",
            "Epoch 132/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33526165504.0000 - val_loss: 32874020864.0000\n",
            "Epoch 133/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33493487616.0000 - val_loss: 32828561408.0000\n",
            "Epoch 134/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33440727040.0000 - val_loss: 32784564224.0000\n",
            "Epoch 135/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33424926720.0000 - val_loss: 32754106368.0000\n",
            "Epoch 136/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33362898944.0000 - val_loss: 32820445184.0000\n",
            "Epoch 137/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33345474560.0000 - val_loss: 32674336768.0000\n",
            "Epoch 138/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33278248960.0000 - val_loss: 32622884864.0000\n",
            "Epoch 139/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33297123328.0000 - val_loss: 32594141184.0000\n",
            "Epoch 140/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33191794688.0000 - val_loss: 32633804800.0000\n",
            "Epoch 141/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33228404736.0000 - val_loss: 32521687040.0000\n",
            "Epoch 142/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33144791040.0000 - val_loss: 32511078400.0000\n",
            "Epoch 143/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33107806208.0000 - val_loss: 32423993344.0000\n",
            "Epoch 144/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 33063161856.0000 - val_loss: 32419016704.0000\n",
            "Epoch 145/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33028050944.0000 - val_loss: 32404842496.0000\n",
            "Epoch 146/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 33051518976.0000 - val_loss: 32326313984.0000\n",
            "Epoch 147/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32931987456.0000 - val_loss: 32311238656.0000\n",
            "Epoch 148/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32931870720.0000 - val_loss: 32302499840.0000\n",
            "Epoch 149/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32967430144.0000 - val_loss: 32229398528.0000\n",
            "Epoch 150/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32882155520.0000 - val_loss: 32202614784.0000\n",
            "Epoch 151/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32824193024.0000 - val_loss: 32179439616.0000\n",
            "Epoch 152/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32800217088.0000 - val_loss: 32164210688.0000\n",
            "Epoch 153/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32756637696.0000 - val_loss: 32114460672.0000\n",
            "Epoch 154/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32726923264.0000 - val_loss: 32068704256.0000\n",
            "Epoch 155/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32683208704.0000 - val_loss: 32080240640.0000\n",
            "Epoch 156/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32674899968.0000 - val_loss: 32023922688.0000\n",
            "Epoch 157/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32633415680.0000 - val_loss: 31990190080.0000\n",
            "Epoch 158/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32610652160.0000 - val_loss: 31930855424.0000\n",
            "Epoch 159/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32593967104.0000 - val_loss: 32009818112.0000\n",
            "Epoch 160/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32576944128.0000 - val_loss: 31921078272.0000\n",
            "Epoch 161/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32509020160.0000 - val_loss: 31856779264.0000\n",
            "Epoch 162/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32480690176.0000 - val_loss: 31840313344.0000\n",
            "Epoch 163/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32478646272.0000 - val_loss: 31811964928.0000\n",
            "Epoch 164/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32422567936.0000 - val_loss: 31761358848.0000\n",
            "Epoch 165/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32418121728.0000 - val_loss: 31750590464.0000\n",
            "Epoch 166/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32394061824.0000 - val_loss: 31714754560.0000\n",
            "Epoch 167/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32389482496.0000 - val_loss: 31773143040.0000\n",
            "Epoch 168/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32340154368.0000 - val_loss: 31703310336.0000\n",
            "Epoch 169/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32331814912.0000 - val_loss: 31645945856.0000\n",
            "Epoch 170/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32282181632.0000 - val_loss: 31615993856.0000\n",
            "Epoch 171/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32250462208.0000 - val_loss: 31601850368.0000\n",
            "Epoch 172/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32201117696.0000 - val_loss: 31569457152.0000\n",
            "Epoch 173/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32164620288.0000 - val_loss: 31608586240.0000\n",
            "Epoch 174/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32166133760.0000 - val_loss: 31515412480.0000\n",
            "Epoch 175/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32142510080.0000 - val_loss: 31485349888.0000\n",
            "Epoch 176/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32132347904.0000 - val_loss: 31543463936.0000\n",
            "Epoch 177/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32069904384.0000 - val_loss: 31449223168.0000\n",
            "Epoch 178/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32118032384.0000 - val_loss: 31482281984.0000\n",
            "Epoch 179/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 32053254144.0000 - val_loss: 31431526400.0000\n",
            "Epoch 180/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32002846720.0000 - val_loss: 31382061056.0000\n",
            "Epoch 181/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31970850816.0000 - val_loss: 31357007872.0000\n",
            "Epoch 182/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 32024434688.0000 - val_loss: 31322171392.0000\n",
            "Epoch 183/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31930499072.0000 - val_loss: 31293292544.0000\n",
            "Epoch 184/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31923808256.0000 - val_loss: 31391866880.0000\n",
            "Epoch 185/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31974248448.0000 - val_loss: 31292465152.0000\n",
            "Epoch 186/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31867545600.0000 - val_loss: 31222028288.0000\n",
            "Epoch 187/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31853742080.0000 - val_loss: 31248234496.0000\n",
            "Epoch 188/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31816095744.0000 - val_loss: 31185004544.0000\n",
            "Epoch 189/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31808061440.0000 - val_loss: 31172450304.0000\n",
            "Epoch 190/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31815237632.0000 - val_loss: 31135490048.0000\n",
            "Epoch 191/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31753990144.0000 - val_loss: 31116222464.0000\n",
            "Epoch 192/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31729119232.0000 - val_loss: 31141636096.0000\n",
            "Epoch 193/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31722901504.0000 - val_loss: 31061022720.0000\n",
            "Epoch 194/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31727007744.0000 - val_loss: 31149535232.0000\n",
            "Epoch 195/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31723925504.0000 - val_loss: 31090532352.0000\n",
            "Epoch 196/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31647242240.0000 - val_loss: 31044919296.0000\n",
            "Epoch 197/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31605866496.0000 - val_loss: 31142696960.0000\n",
            "Epoch 198/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31639541760.0000 - val_loss: 30953043968.0000\n",
            "Epoch 199/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31595524096.0000 - val_loss: 30950938624.0000\n",
            "Epoch 200/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31620585472.0000 - val_loss: 30936952832.0000\n",
            "Epoch 201/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31537930240.0000 - val_loss: 30909548544.0000\n",
            "Epoch 202/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31529379840.0000 - val_loss: 30910150656.0000\n",
            "Epoch 203/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31565744128.0000 - val_loss: 30869329920.0000\n",
            "Epoch 204/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31482284032.0000 - val_loss: 30865291264.0000\n",
            "Epoch 205/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31491665920.0000 - val_loss: 31015964672.0000\n",
            "Epoch 206/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31458826240.0000 - val_loss: 30810415104.0000\n",
            "Epoch 207/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31450218496.0000 - val_loss: 30795141120.0000\n",
            "Epoch 208/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31426492416.0000 - val_loss: 30780276736.0000\n",
            "Epoch 209/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31409911808.0000 - val_loss: 30763659264.0000\n",
            "Epoch 210/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31371122688.0000 - val_loss: 30760867840.0000\n",
            "Epoch 211/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31368034304.0000 - val_loss: 30724265984.0000\n",
            "Epoch 212/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31308771328.0000 - val_loss: 30793568256.0000\n",
            "Epoch 213/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31322669056.0000 - val_loss: 30699595776.0000\n",
            "Epoch 214/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31353333760.0000 - val_loss: 30684043264.0000\n",
            "Epoch 215/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31285028864.0000 - val_loss: 30709463040.0000\n",
            "Epoch 216/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31283959808.0000 - val_loss: 30642307072.0000\n",
            "Epoch 217/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31266777088.0000 - val_loss: 30622885888.0000\n",
            "Epoch 218/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31221895168.0000 - val_loss: 30614284288.0000\n",
            "Epoch 219/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31212173312.0000 - val_loss: 30588448768.0000\n",
            "Epoch 220/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31210999808.0000 - val_loss: 30593757184.0000\n",
            "Epoch 221/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31195320320.0000 - val_loss: 30545248256.0000\n",
            "Epoch 222/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31184455680.0000 - val_loss: 30565398528.0000\n",
            "Epoch 223/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31153928192.0000 - val_loss: 30515435520.0000\n",
            "Epoch 224/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31168143360.0000 - val_loss: 30504425472.0000\n",
            "Epoch 225/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31136794624.0000 - val_loss: 30546763776.0000\n",
            "Epoch 226/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 31100921856.0000 - val_loss: 30481899520.0000\n",
            "Epoch 227/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31085088768.0000 - val_loss: 30551883776.0000\n",
            "Epoch 228/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31070103552.0000 - val_loss: 30551312384.0000\n",
            "Epoch 229/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31040194560.0000 - val_loss: 30452486144.0000\n",
            "Epoch 230/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31013683200.0000 - val_loss: 30422528000.0000\n",
            "Epoch 231/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31017842688.0000 - val_loss: 30466271232.0000\n",
            "Epoch 232/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30998231040.0000 - val_loss: 30456139776.0000\n",
            "Epoch 233/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 31065591808.0000 - val_loss: 30379915264.0000\n",
            "Epoch 234/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30951305216.0000 - val_loss: 30387458048.0000\n",
            "Epoch 235/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30996602880.0000 - val_loss: 30345246720.0000\n",
            "Epoch 236/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30946426880.0000 - val_loss: 30348244992.0000\n",
            "Epoch 237/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30969432064.0000 - val_loss: 30712037376.0000\n",
            "Epoch 238/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30917793792.0000 - val_loss: 30344118272.0000\n",
            "Epoch 239/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30898524160.0000 - val_loss: 30301624320.0000\n",
            "Epoch 240/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30878855168.0000 - val_loss: 30309939200.0000\n",
            "Epoch 241/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30903408640.0000 - val_loss: 30437050368.0000\n",
            "Epoch 242/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30849478656.0000 - val_loss: 30282717184.0000\n",
            "Epoch 243/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30826192896.0000 - val_loss: 30230607872.0000\n",
            "Epoch 244/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30811154432.0000 - val_loss: 30226597888.0000\n",
            "Epoch 245/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30785931264.0000 - val_loss: 30344679424.0000\n",
            "Epoch 246/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30807011328.0000 - val_loss: 30244349952.0000\n",
            "Epoch 247/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30784290816.0000 - val_loss: 30233536512.0000\n",
            "Epoch 248/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30763210752.0000 - val_loss: 30176616448.0000\n",
            "Epoch 249/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30721249280.0000 - val_loss: 30148470784.0000\n",
            "Epoch 250/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30774986752.0000 - val_loss: 30171924480.0000\n",
            "Epoch 251/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30687246336.0000 - val_loss: 30311092224.0000\n",
            "Epoch 252/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30744344576.0000 - val_loss: 30119651328.0000\n",
            "Epoch 253/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30661756928.0000 - val_loss: 30139146240.0000\n",
            "Epoch 254/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30648561664.0000 - val_loss: 30097055744.0000\n",
            "Epoch 255/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30689204224.0000 - val_loss: 30098380800.0000\n",
            "Epoch 256/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30617794560.0000 - val_loss: 30053566464.0000\n",
            "Epoch 257/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30623227904.0000 - val_loss: 30082887680.0000\n",
            "Epoch 258/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30599202816.0000 - val_loss: 30086410240.0000\n",
            "Epoch 259/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30579394560.0000 - val_loss: 30061031424.0000\n",
            "Epoch 260/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30564126720.0000 - val_loss: 30029205504.0000\n",
            "Epoch 261/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30596694016.0000 - val_loss: 30062848000.0000\n",
            "Epoch 262/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30547605504.0000 - val_loss: 29992876032.0000\n",
            "Epoch 263/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30512230400.0000 - val_loss: 29978517504.0000\n",
            "Epoch 264/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30500085760.0000 - val_loss: 30006384640.0000\n",
            "Epoch 265/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30520334336.0000 - val_loss: 29952264192.0000\n",
            "Epoch 266/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30473117696.0000 - val_loss: 29940307968.0000\n",
            "Epoch 267/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30452883456.0000 - val_loss: 29938313216.0000\n",
            "Epoch 268/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30434557952.0000 - val_loss: 29921372160.0000\n",
            "Epoch 269/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30464555008.0000 - val_loss: 29922764800.0000\n",
            "Epoch 270/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30375024640.0000 - val_loss: 29995657216.0000\n",
            "Epoch 271/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30392008704.0000 - val_loss: 29904926720.0000\n",
            "Epoch 272/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30395289600.0000 - val_loss: 29886963712.0000\n",
            "Epoch 273/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30434828288.0000 - val_loss: 29896804352.0000\n",
            "Epoch 274/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30385395712.0000 - val_loss: 29853544448.0000\n",
            "Epoch 275/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30414239744.0000 - val_loss: 29858879488.0000\n",
            "Epoch 276/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30337740800.0000 - val_loss: 29883402240.0000\n",
            "Epoch 277/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30367645696.0000 - val_loss: 29830252544.0000\n",
            "Epoch 278/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30333118464.0000 - val_loss: 29816502272.0000\n",
            "Epoch 279/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30296971264.0000 - val_loss: 29807484928.0000\n",
            "Epoch 280/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30286993408.0000 - val_loss: 29818988544.0000\n",
            "Epoch 281/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30312069120.0000 - val_loss: 29850413056.0000\n",
            "Epoch 282/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30235815936.0000 - val_loss: 29836238848.0000\n",
            "Epoch 283/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30213242880.0000 - val_loss: 29776453632.0000\n",
            "Epoch 284/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30217525248.0000 - val_loss: 29781794816.0000\n",
            "Epoch 285/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30236690432.0000 - val_loss: 29757974528.0000\n",
            "Epoch 286/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30189502464.0000 - val_loss: 29745383424.0000\n",
            "Epoch 287/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30195845120.0000 - val_loss: 29740029952.0000\n",
            "Epoch 288/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30258698240.0000 - val_loss: 29770721280.0000\n",
            "Epoch 289/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30192283648.0000 - val_loss: 29825054720.0000\n",
            "Epoch 290/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30141444096.0000 - val_loss: 29843320832.0000\n",
            "Epoch 291/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30133491712.0000 - val_loss: 29688989696.0000\n",
            "Epoch 292/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30111811584.0000 - val_loss: 29705295872.0000\n",
            "Epoch 293/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30065491968.0000 - val_loss: 29826416640.0000\n",
            "Epoch 294/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 30080866304.0000 - val_loss: 29696110592.0000\n",
            "Epoch 295/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30103080960.0000 - val_loss: 29712506880.0000\n",
            "Epoch 296/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30034784256.0000 - val_loss: 29667698688.0000\n",
            "Epoch 297/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30066599936.0000 - val_loss: 29697126400.0000\n",
            "Epoch 298/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30015391744.0000 - val_loss: 29752690688.0000\n",
            "Epoch 299/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30026297344.0000 - val_loss: 29616852992.0000\n",
            "Epoch 300/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30015791104.0000 - val_loss: 29623021568.0000\n",
            "Epoch 301/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30024347648.0000 - val_loss: 29668157440.0000\n",
            "Epoch 302/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30019577856.0000 - val_loss: 29695318016.0000\n",
            "Epoch 303/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 30008430592.0000 - val_loss: 29650059264.0000\n",
            "Epoch 304/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29953157120.0000 - val_loss: 29533177856.0000\n",
            "Epoch 305/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29931239424.0000 - val_loss: 29642215424.0000\n",
            "Epoch 306/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29942073344.0000 - val_loss: 29526325248.0000\n",
            "Epoch 307/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29919606784.0000 - val_loss: 29538312192.0000\n",
            "Epoch 308/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29963878400.0000 - val_loss: 29500459008.0000\n",
            "Epoch 309/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29909213184.0000 - val_loss: 29549207552.0000\n",
            "Epoch 310/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29884536832.0000 - val_loss: 29488549888.0000\n",
            "Epoch 311/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29878859776.0000 - val_loss: 29474297856.0000\n",
            "Epoch 312/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29887162368.0000 - val_loss: 29501483008.0000\n",
            "Epoch 313/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29860220928.0000 - val_loss: 29534334976.0000\n",
            "Epoch 314/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29863133184.0000 - val_loss: 29473818624.0000\n",
            "Epoch 315/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29830119424.0000 - val_loss: 29466744832.0000\n",
            "Epoch 316/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29800695808.0000 - val_loss: 29431422976.0000\n",
            "Epoch 317/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29775095808.0000 - val_loss: 29566457856.0000\n",
            "Epoch 318/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29819226112.0000 - val_loss: 29482231808.0000\n",
            "Epoch 319/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29784578048.0000 - val_loss: 29437265920.0000\n",
            "Epoch 320/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29787334656.0000 - val_loss: 29401042944.0000\n",
            "Epoch 321/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29736151040.0000 - val_loss: 29433667584.0000\n",
            "Epoch 322/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29755502592.0000 - val_loss: 29382871040.0000\n",
            "Epoch 323/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29699504128.0000 - val_loss: 29617281024.0000\n",
            "Epoch 324/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29698912256.0000 - val_loss: 29432799232.0000\n",
            "Epoch 325/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29709633536.0000 - val_loss: 29369374720.0000\n",
            "Epoch 326/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29717710848.0000 - val_loss: 29359960064.0000\n",
            "Epoch 327/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29655578624.0000 - val_loss: 29340155904.0000\n",
            "Epoch 328/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29644521472.0000 - val_loss: 29322350592.0000\n",
            "Epoch 329/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29623099392.0000 - val_loss: 29305415680.0000\n",
            "Epoch 330/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29585526784.0000 - val_loss: 29525209088.0000\n",
            "Epoch 331/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29656252416.0000 - val_loss: 29298034688.0000\n",
            "Epoch 332/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29597300736.0000 - val_loss: 29301024768.0000\n",
            "Epoch 333/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29556074496.0000 - val_loss: 29380548608.0000\n",
            "Epoch 334/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29583808512.0000 - val_loss: 29258758144.0000\n",
            "Epoch 335/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29650632704.0000 - val_loss: 29293256704.0000\n",
            "Epoch 336/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29534920704.0000 - val_loss: 29246085120.0000\n",
            "Epoch 337/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29562923008.0000 - val_loss: 29222858752.0000\n",
            "Epoch 338/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29544056832.0000 - val_loss: 29249728512.0000\n",
            "Epoch 339/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29513211904.0000 - val_loss: 29290043392.0000\n",
            "Epoch 340/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29461694464.0000 - val_loss: 29306134528.0000\n",
            "Epoch 341/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29583476736.0000 - val_loss: 29195192320.0000\n",
            "Epoch 342/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29467877376.0000 - val_loss: 29224728576.0000\n",
            "Epoch 343/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29457807360.0000 - val_loss: 29181542400.0000\n",
            "Epoch 344/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29415464960.0000 - val_loss: 29168101376.0000\n",
            "Epoch 345/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29426327552.0000 - val_loss: 29146718208.0000\n",
            "Epoch 346/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29440104448.0000 - val_loss: 29165383680.0000\n",
            "Epoch 347/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29397413888.0000 - val_loss: 29163636736.0000\n",
            "Epoch 348/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29366841344.0000 - val_loss: 29140856832.0000\n",
            "Epoch 349/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29368610816.0000 - val_loss: 29142425600.0000\n",
            "Epoch 350/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29349519360.0000 - val_loss: 29124208640.0000\n",
            "Epoch 351/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29360709632.0000 - val_loss: 29124548608.0000\n",
            "Epoch 352/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29313374208.0000 - val_loss: 29088399360.0000\n",
            "Epoch 353/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29304340480.0000 - val_loss: 29120786432.0000\n",
            "Epoch 354/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29334464512.0000 - val_loss: 29134796800.0000\n",
            "Epoch 355/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29270593536.0000 - val_loss: 29048365056.0000\n",
            "Epoch 356/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29296836608.0000 - val_loss: 29049800704.0000\n",
            "Epoch 357/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29278408704.0000 - val_loss: 29127663616.0000\n",
            "Epoch 358/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29242374144.0000 - val_loss: 29034876928.0000\n",
            "Epoch 359/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29297168384.0000 - val_loss: 29046087680.0000\n",
            "Epoch 360/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29270067200.0000 - val_loss: 29040615424.0000\n",
            "Epoch 361/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29225459712.0000 - val_loss: 28997484544.0000\n",
            "Epoch 362/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29205301248.0000 - val_loss: 28978966528.0000\n",
            "Epoch 363/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29171990528.0000 - val_loss: 29091653632.0000\n",
            "Epoch 364/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29149478912.0000 - val_loss: 29027661824.0000\n",
            "Epoch 365/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29161508864.0000 - val_loss: 28953319424.0000\n",
            "Epoch 366/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29120397312.0000 - val_loss: 29070751744.0000\n",
            "Epoch 367/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29115856896.0000 - val_loss: 28930760704.0000\n",
            "Epoch 368/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29201256448.0000 - val_loss: 28966060032.0000\n",
            "Epoch 369/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29121812480.0000 - val_loss: 28914528256.0000\n",
            "Epoch 370/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29066907648.0000 - val_loss: 28899237888.0000\n",
            "Epoch 371/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29085263872.0000 - val_loss: 28931110912.0000\n",
            "Epoch 372/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29030733824.0000 - val_loss: 28888188928.0000\n",
            "Epoch 373/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29039298560.0000 - val_loss: 28873502720.0000\n",
            "Epoch 374/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 29010059264.0000 - val_loss: 28873224192.0000\n",
            "Epoch 375/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 29023049728.0000 - val_loss: 28946784256.0000\n",
            "Epoch 376/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28991813632.0000 - val_loss: 28867446784.0000\n",
            "Epoch 377/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28977735680.0000 - val_loss: 28869347328.0000\n",
            "Epoch 378/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28992894976.0000 - val_loss: 28829161472.0000\n",
            "Epoch 379/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28958822400.0000 - val_loss: 28947408896.0000\n",
            "Epoch 380/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28966174720.0000 - val_loss: 29005506560.0000\n",
            "Epoch 381/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28956428288.0000 - val_loss: 28792279040.0000\n",
            "Epoch 382/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28887109632.0000 - val_loss: 28770834432.0000\n",
            "Epoch 383/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28866480128.0000 - val_loss: 28790171648.0000\n",
            "Epoch 384/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28918114304.0000 - val_loss: 28768110592.0000\n",
            "Epoch 385/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28876255232.0000 - val_loss: 28767582208.0000\n",
            "Epoch 386/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28852645888.0000 - val_loss: 29050849280.0000\n",
            "Epoch 387/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28889407488.0000 - val_loss: 28788500480.0000\n",
            "Epoch 388/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28800847872.0000 - val_loss: 28689481728.0000\n",
            "Epoch 389/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28776296448.0000 - val_loss: 28833456128.0000\n",
            "Epoch 390/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28789700608.0000 - val_loss: 28697636864.0000\n",
            "Epoch 391/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28777715712.0000 - val_loss: 28941627392.0000\n",
            "Epoch 392/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28743657472.0000 - val_loss: 28651331584.0000\n",
            "Epoch 393/400\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 28710426624.0000 - val_loss: 28639221760.0000\n",
            "Epoch 394/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28689473536.0000 - val_loss: 28789839872.0000\n",
            "Epoch 395/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28658354176.0000 - val_loss: 28626231296.0000\n",
            "Epoch 396/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28662960128.0000 - val_loss: 28789907456.0000\n",
            "Epoch 397/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28735809536.0000 - val_loss: 28637198336.0000\n",
            "Epoch 398/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28621326336.0000 - val_loss: 28785879040.0000\n",
            "Epoch 399/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28661022720.0000 - val_loss: 28659705856.0000\n",
            "Epoch 400/400\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 28564131840.0000 - val_loss: 28573728768.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x26748d459c0>"
            ]
          },
          "execution_count": 323,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=X_train,y=y_train.values,\n",
        "          validation_data=(X_test,y_test.values),\n",
        "          batch_size=128,epochs=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa2L4IWbKQKp"
      },
      "source": [
        "<a id=\"ch9\"></a>\n",
        "## Evaluation on test data\n",
        "---\n",
        "### Regression Evaluation Metrics\n",
        "\n",
        "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
        "\n",
        "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
        "\n",
        "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
        "\n",
        "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
        "\n",
        "Comparing these metrics:\n",
        "\n",
        "- **MAE** is the easiest to understand, because it's the average error.\n",
        "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
        "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTq3u5UPKQKp"
      },
      "source": [
        "### Predicting on brand new data\n",
        "In this part we are giving the model the test set to get a list of predictions. Then we compare the correct values with the list of predictions. We use different metrics to compare the predictions, in this case we use MAE, MSE, RMSE and Variance Regression Score.\n",
        "\n",
        "Let us start by analyzing the MAE, which is \\\\$103,500. This means that our model is off on average about \\\\$100,000.\n",
        "\n",
        "***Is that MAE good or bad?***\n",
        "\n",
        "For that we must take into account our original data set and see what kind of values we have. For instance, the mean is 540,000, therefore the MEA is about 19% of the mean price. This is not a particularly good result.\n",
        "\n",
        "To better understand this error, we can use the variance regression score, where the best possible score is 1.0 and lower values are worse. This tells you how much variance is being explain by your model. In our case we have 0.80 which is a normal result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "_kg_hide-input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSn4Uj1VKQKp",
        "outputId": "8bce4f8c-5f0a-4a8b-a6dc-5c0c136ca259",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203/203 [==============================] - 0s 1ms/step\n",
            "MAE:  104101.97558172038\n",
            "MSE:  28573731467.21278\n",
            "RMSE:  169037.66286603935\n",
            "Variance Regression Score:  0.7964006601429703\n",
            "\n",
            "\n",
            "Descriptive Statistics:\n",
            " count    2.161300e+04\n",
            "mean     5.400881e+05\n",
            "std      3.671272e+05\n",
            "min      7.500000e+04\n",
            "25%      3.219500e+05\n",
            "50%      4.500000e+05\n",
            "75%      6.450000e+05\n",
            "max      7.700000e+06\n",
            "Name: price, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print('MAE: ',mean_absolute_error(y_test,predictions))\n",
        "print('MSE: ',mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ',np.sqrt(mean_squared_error(y_test,predictions)))\n",
        "print('Variance Regression Score: ',explained_variance_score(y_test,predictions))\n",
        "\n",
        "print('\\n\\nDescriptive Statistics:\\n',df['price'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Persisting the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo guardado en /Users/SISTEMAS/MLOPS-PROJECT/house_price_prediction/house_price_prediction/models/neural_network_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "TRAINED_MODEL_DIR = '/Users/SISTEMAS/MLOPS-PROJECT/house_price_prediction/house_price_prediction/models/'\n",
        "# Guardar la red neuronal en un archivo .pkl\n",
        "FILE_NAME = 'neural_network_model.pkl'\n",
        "joblib.dump(model, TRAINED_MODEL_DIR+FILE_NAME)\n",
        "print(f\"Modelo guardado en {TRAINED_MODEL_DIR+FILE_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicting on a brand new house\n",
        "---\n",
        "We are going to use the model to predict the price on a brand-new house. We are going to choose the first house of the data set and drop the price. single_house is going to have all the features that we need to predict the price. After that we need to reshape the variable and scale the features.\n",
        "\n",
        "The original price is \\\\$221,900 and the model prediction is \\\\$280,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "_kg_hide-input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apgZE3YGKQKq",
        "outputId": "4a623331-623a-4209-ab76-23c6bcb2b221",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features of new house:\n",
            "bedrooms            3.0000\n",
            "bathrooms           1.0000\n",
            "sqft_living      1180.0000\n",
            "sqft_lot         5650.0000\n",
            "floors              1.0000\n",
            "waterfront          0.0000\n",
            "view                0.0000\n",
            "condition           3.0000\n",
            "grade               7.0000\n",
            "sqft_above       1180.0000\n",
            "sqft_basement       0.0000\n",
            "yr_built         1955.0000\n",
            "yr_renovated        0.0000\n",
            "lat                47.5112\n",
            "long             -122.2570\n",
            "sqft_living15    1340.0000\n",
            "sqft_lot15       5650.0000\n",
            "month              10.0000\n",
            "year             2014.0000\n",
            "Name: 0, dtype: float64\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "Prediction Price: 270773.97\n",
            "\n",
            "Original Price: 221900.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\SISTEMAS\\MLOPS-PROJECT\\.venv\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# fueatures of new house\n",
        "single_house = df.drop('price',axis=1).iloc[0]\n",
        "print(f'Features of new house:\\n{single_house}')\n",
        "\n",
        "# reshape the numpy array and scale the features\n",
        "single_house = scaler.transform(single_house.values.reshape(-1, 19))\n",
        "\n",
        "# run the model and get the price prediction\n",
        "print('\\nPrediction Price:',model.predict(single_house)[0,0])\n",
        "\n",
        "# original price\n",
        "print('\\nOriginal Price:',df.iloc[0]['price'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
